{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87da94bc-bbaa-4ef4-a83a-c2f7a385316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8956d6-9b10-4fbe-9bc7-ffc4604e14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx_reverse_topological_sort import (\n",
    "    reverse_topological_generations,\n",
    "    reverse_topological_sort,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdf4bff-8324-400e-b329-4c7aecb4ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_oss_simplified import GptOssForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afea395b-943f-4356-a60a-23951931a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code: assign tensors as you yield them\n",
    "model = GptOssForCausalLM()       # Uninitialized, or on your desired device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1f960f-ce13-41be-8aec-aa8c99244443",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodule_path_graph = nx.DiGraph()\n",
    "submodule_paths_to_sumbodules = {}\n",
    "submodule_paths_to_submodule_types = {}\n",
    "submodule_types_to_submodules = {}\n",
    "\n",
    "for submodule_path, submodule in model.named_modules():\n",
    "    submodule_path_graph.add_node(submodule_path)\n",
    "    submodule_path_components = submodule_path.split('.') if submodule_path else []\n",
    "    if len(submodule_path_components) == 0:\n",
    "        pass\n",
    "    elif len(submodule_path_components) == 1:\n",
    "        submodule_path_graph.add_edge('', submodule_path)\n",
    "    elif len(submodule_path_components) >= 2:\n",
    "        parent_submodule_path = '.'.join(submodule_path_components[:-1])\n",
    "        submodule_path_graph.add_edge(parent_submodule_path, submodule_path)\n",
    "\n",
    "    submodule_paths_to_sumbodules[submodule_path] = submodule\n",
    "    \n",
    "    submodule_type = type(submodule)\n",
    "    submodule_paths_to_submodule_types[submodule_path] = submodule_type\n",
    "    submodule_types_to_submodules.setdefault(submodule_type, []).append(submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f04566b-1546-49a0-90f6-812dcf5db146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.embed_tokens',\n",
       " 'model.layers.0.self_attn.q_proj',\n",
       " 'model.layers.0.self_attn.k_proj',\n",
       " 'model.layers.0.self_attn.v_proj',\n",
       " 'model.layers.0.self_attn.o_proj',\n",
       " 'model.layers.0.mlp.router',\n",
       " 'model.layers.0.mlp.experts',\n",
       " 'model.layers.0.input_layernorm',\n",
       " 'model.layers.0.post_attention_layernorm',\n",
       " 'model.layers.1.self_attn.q_proj',\n",
       " 'model.layers.1.self_attn.k_proj',\n",
       " 'model.layers.1.self_attn.v_proj',\n",
       " 'model.layers.1.self_attn.o_proj',\n",
       " 'model.layers.1.mlp.router',\n",
       " 'model.layers.1.mlp.experts',\n",
       " 'model.layers.1.input_layernorm',\n",
       " 'model.layers.1.post_attention_layernorm',\n",
       " 'model.layers.2.self_attn.q_proj',\n",
       " 'model.layers.2.self_attn.k_proj',\n",
       " 'model.layers.2.self_attn.v_proj',\n",
       " 'model.layers.2.self_attn.o_proj',\n",
       " 'model.layers.2.mlp.router',\n",
       " 'model.layers.2.mlp.experts',\n",
       " 'model.layers.2.input_layernorm',\n",
       " 'model.layers.2.post_attention_layernorm',\n",
       " 'model.layers.3.self_attn.q_proj',\n",
       " 'model.layers.3.self_attn.k_proj',\n",
       " 'model.layers.3.self_attn.v_proj',\n",
       " 'model.layers.3.self_attn.o_proj',\n",
       " 'model.layers.3.mlp.router',\n",
       " 'model.layers.3.mlp.experts',\n",
       " 'model.layers.3.input_layernorm',\n",
       " 'model.layers.3.post_attention_layernorm',\n",
       " 'model.layers.4.self_attn.q_proj',\n",
       " 'model.layers.4.self_attn.k_proj',\n",
       " 'model.layers.4.self_attn.v_proj',\n",
       " 'model.layers.4.self_attn.o_proj',\n",
       " 'model.layers.4.mlp.router',\n",
       " 'model.layers.4.mlp.experts',\n",
       " 'model.layers.4.input_layernorm',\n",
       " 'model.layers.4.post_attention_layernorm',\n",
       " 'model.layers.5.self_attn.q_proj',\n",
       " 'model.layers.5.self_attn.k_proj',\n",
       " 'model.layers.5.self_attn.v_proj',\n",
       " 'model.layers.5.self_attn.o_proj',\n",
       " 'model.layers.5.mlp.router',\n",
       " 'model.layers.5.mlp.experts',\n",
       " 'model.layers.5.input_layernorm',\n",
       " 'model.layers.5.post_attention_layernorm',\n",
       " 'model.layers.6.self_attn.q_proj',\n",
       " 'model.layers.6.self_attn.k_proj',\n",
       " 'model.layers.6.self_attn.v_proj',\n",
       " 'model.layers.6.self_attn.o_proj',\n",
       " 'model.layers.6.mlp.router',\n",
       " 'model.layers.6.mlp.experts',\n",
       " 'model.layers.6.input_layernorm',\n",
       " 'model.layers.6.post_attention_layernorm',\n",
       " 'model.layers.7.self_attn.q_proj',\n",
       " 'model.layers.7.self_attn.k_proj',\n",
       " 'model.layers.7.self_attn.v_proj',\n",
       " 'model.layers.7.self_attn.o_proj',\n",
       " 'model.layers.7.mlp.router',\n",
       " 'model.layers.7.mlp.experts',\n",
       " 'model.layers.7.input_layernorm',\n",
       " 'model.layers.7.post_attention_layernorm',\n",
       " 'model.layers.8.self_attn.q_proj',\n",
       " 'model.layers.8.self_attn.k_proj',\n",
       " 'model.layers.8.self_attn.v_proj',\n",
       " 'model.layers.8.self_attn.o_proj',\n",
       " 'model.layers.8.mlp.router',\n",
       " 'model.layers.8.mlp.experts',\n",
       " 'model.layers.8.input_layernorm',\n",
       " 'model.layers.8.post_attention_layernorm',\n",
       " 'model.layers.9.self_attn.q_proj',\n",
       " 'model.layers.9.self_attn.k_proj',\n",
       " 'model.layers.9.self_attn.v_proj',\n",
       " 'model.layers.9.self_attn.o_proj',\n",
       " 'model.layers.9.mlp.router',\n",
       " 'model.layers.9.mlp.experts',\n",
       " 'model.layers.9.input_layernorm',\n",
       " 'model.layers.9.post_attention_layernorm',\n",
       " 'model.layers.10.self_attn.q_proj',\n",
       " 'model.layers.10.self_attn.k_proj',\n",
       " 'model.layers.10.self_attn.v_proj',\n",
       " 'model.layers.10.self_attn.o_proj',\n",
       " 'model.layers.10.mlp.router',\n",
       " 'model.layers.10.mlp.experts',\n",
       " 'model.layers.10.input_layernorm',\n",
       " 'model.layers.10.post_attention_layernorm',\n",
       " 'model.layers.11.self_attn.q_proj',\n",
       " 'model.layers.11.self_attn.k_proj',\n",
       " 'model.layers.11.self_attn.v_proj',\n",
       " 'model.layers.11.self_attn.o_proj',\n",
       " 'model.layers.11.mlp.router',\n",
       " 'model.layers.11.mlp.experts',\n",
       " 'model.layers.11.input_layernorm',\n",
       " 'model.layers.11.post_attention_layernorm',\n",
       " 'model.layers.12.self_attn.q_proj',\n",
       " 'model.layers.12.self_attn.k_proj',\n",
       " 'model.layers.12.self_attn.v_proj',\n",
       " 'model.layers.12.self_attn.o_proj',\n",
       " 'model.layers.12.mlp.router',\n",
       " 'model.layers.12.mlp.experts',\n",
       " 'model.layers.12.input_layernorm',\n",
       " 'model.layers.12.post_attention_layernorm',\n",
       " 'model.layers.13.self_attn.q_proj',\n",
       " 'model.layers.13.self_attn.k_proj',\n",
       " 'model.layers.13.self_attn.v_proj',\n",
       " 'model.layers.13.self_attn.o_proj',\n",
       " 'model.layers.13.mlp.router',\n",
       " 'model.layers.13.mlp.experts',\n",
       " 'model.layers.13.input_layernorm',\n",
       " 'model.layers.13.post_attention_layernorm',\n",
       " 'model.layers.14.self_attn.q_proj',\n",
       " 'model.layers.14.self_attn.k_proj',\n",
       " 'model.layers.14.self_attn.v_proj',\n",
       " 'model.layers.14.self_attn.o_proj',\n",
       " 'model.layers.14.mlp.router',\n",
       " 'model.layers.14.mlp.experts',\n",
       " 'model.layers.14.input_layernorm',\n",
       " 'model.layers.14.post_attention_layernorm',\n",
       " 'model.layers.15.self_attn.q_proj',\n",
       " 'model.layers.15.self_attn.k_proj',\n",
       " 'model.layers.15.self_attn.v_proj',\n",
       " 'model.layers.15.self_attn.o_proj',\n",
       " 'model.layers.15.mlp.router',\n",
       " 'model.layers.15.mlp.experts',\n",
       " 'model.layers.15.input_layernorm',\n",
       " 'model.layers.15.post_attention_layernorm',\n",
       " 'model.layers.16.self_attn.q_proj',\n",
       " 'model.layers.16.self_attn.k_proj',\n",
       " 'model.layers.16.self_attn.v_proj',\n",
       " 'model.layers.16.self_attn.o_proj',\n",
       " 'model.layers.16.mlp.router',\n",
       " 'model.layers.16.mlp.experts',\n",
       " 'model.layers.16.input_layernorm',\n",
       " 'model.layers.16.post_attention_layernorm',\n",
       " 'model.layers.17.self_attn.q_proj',\n",
       " 'model.layers.17.self_attn.k_proj',\n",
       " 'model.layers.17.self_attn.v_proj',\n",
       " 'model.layers.17.self_attn.o_proj',\n",
       " 'model.layers.17.mlp.router',\n",
       " 'model.layers.17.mlp.experts',\n",
       " 'model.layers.17.input_layernorm',\n",
       " 'model.layers.17.post_attention_layernorm',\n",
       " 'model.layers.18.self_attn.q_proj',\n",
       " 'model.layers.18.self_attn.k_proj',\n",
       " 'model.layers.18.self_attn.v_proj',\n",
       " 'model.layers.18.self_attn.o_proj',\n",
       " 'model.layers.18.mlp.router',\n",
       " 'model.layers.18.mlp.experts',\n",
       " 'model.layers.18.input_layernorm',\n",
       " 'model.layers.18.post_attention_layernorm',\n",
       " 'model.layers.19.self_attn.q_proj',\n",
       " 'model.layers.19.self_attn.k_proj',\n",
       " 'model.layers.19.self_attn.v_proj',\n",
       " 'model.layers.19.self_attn.o_proj',\n",
       " 'model.layers.19.mlp.router',\n",
       " 'model.layers.19.mlp.experts',\n",
       " 'model.layers.19.input_layernorm',\n",
       " 'model.layers.19.post_attention_layernorm',\n",
       " 'model.layers.20.self_attn.q_proj',\n",
       " 'model.layers.20.self_attn.k_proj',\n",
       " 'model.layers.20.self_attn.v_proj',\n",
       " 'model.layers.20.self_attn.o_proj',\n",
       " 'model.layers.20.mlp.router',\n",
       " 'model.layers.20.mlp.experts',\n",
       " 'model.layers.20.input_layernorm',\n",
       " 'model.layers.20.post_attention_layernorm',\n",
       " 'model.layers.21.self_attn.q_proj',\n",
       " 'model.layers.21.self_attn.k_proj',\n",
       " 'model.layers.21.self_attn.v_proj',\n",
       " 'model.layers.21.self_attn.o_proj',\n",
       " 'model.layers.21.mlp.router',\n",
       " 'model.layers.21.mlp.experts',\n",
       " 'model.layers.21.input_layernorm',\n",
       " 'model.layers.21.post_attention_layernorm',\n",
       " 'model.layers.22.self_attn.q_proj',\n",
       " 'model.layers.22.self_attn.k_proj',\n",
       " 'model.layers.22.self_attn.v_proj',\n",
       " 'model.layers.22.self_attn.o_proj',\n",
       " 'model.layers.22.mlp.router',\n",
       " 'model.layers.22.mlp.experts',\n",
       " 'model.layers.22.input_layernorm',\n",
       " 'model.layers.22.post_attention_layernorm',\n",
       " 'model.layers.23.self_attn.q_proj',\n",
       " 'model.layers.23.self_attn.k_proj',\n",
       " 'model.layers.23.self_attn.v_proj',\n",
       " 'model.layers.23.self_attn.o_proj',\n",
       " 'model.layers.23.mlp.router',\n",
       " 'model.layers.23.mlp.experts',\n",
       " 'model.layers.23.input_layernorm',\n",
       " 'model.layers.23.post_attention_layernorm',\n",
       " 'model.norm',\n",
       " 'model.rotary_emb',\n",
       " 'lm_head']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_generation = next(reverse_topological_generations(submodule_path_graph))\n",
    "first_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae997fcc-ea38-4e44-b5c6-df2728f2b915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{gpt_oss_simplified.GptOssExperts,\n",
       " gpt_oss_simplified.GptOssRMSNorm,\n",
       " gpt_oss_simplified.GptOssRotaryEmbedding,\n",
       " gpt_oss_simplified.GptOssTopKRouter,\n",
       " torch.nn.modules.linear.Linear,\n",
       " torch.nn.modules.sparse.Embedding}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{submodule_paths_to_submodule_types[p] for p in first_generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54864ae6-0425-4f7a-a067-f1913810e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(201088, 2880, padding_idx=199999)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=4096, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=2880, out_features=512, bias=True)\n",
      "Linear(in_features=4096, out_features=2880, bias=True)\n",
      "Linear(in_features=2880, out_features=201088, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for p in first_generation:\n",
    "    t = submodule_paths_to_submodule_types[p]\n",
    "    if t.__module__.startswith('torch'):\n",
    "        m = submodule_paths_to_sumbodules[p]\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a578e7aa-a387-49d8-ac14-008601f8275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af61e0c7-e0d2-4776-aeac-ca08a43f2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_submodule_types_to_parameter_names_to_getters = {\n",
    "    torch.nn.Embedding: {\n",
    "        'num_embeddings': lambda submodule: submodule.num_embeddings,\n",
    "        'embedding_dim': lambda submodule: submodule.embedding_dim,\n",
    "        'padding_idx': lambda submodule: submodule.padding_idx,\n",
    "    },\n",
    "    torch.nn.Linear: {\n",
    "        'in_features': lambda submodule: submodule.in_features,\n",
    "        'out_features': lambda submodule: submodule.out_features,\n",
    "        'bias': lambda submodule: submodule.bias is not None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c45d71-6275-448f-b21a-265ef78d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_submodule_paths_to_parameter_dicts = {}\n",
    "for p in first_generation:\n",
    "    t = submodule_paths_to_submodule_types[p]\n",
    "    if t.__module__.startswith('torch'):\n",
    "        m = submodule_paths_to_sumbodules[p]\n",
    "        parameter_names_to_getters = first_level_submodule_types_to_parameter_names_to_getters[t]\n",
    "        first_level_submodule_paths_to_parameter_dicts[p] = {\n",
    "            parameter_name: getter(m)\n",
    "            for parameter_name, getter in parameter_names_to_getters.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1f9c59-e691-4902-a933-7827dcbd04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b73a1c-8266-4158-a5dc-ed37fee2af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model.embed_tokens\": {\n",
      "    \"num_embeddings\": 201088,\n",
      "    \"embedding_dim\": 2880,\n",
      "    \"padding_idx\": 199999\n",
      "  },\n",
      "  \"model.layers.0.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.0.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.0.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.0.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.1.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.1.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.1.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.1.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.2.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.2.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.2.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.2.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.3.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.3.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.3.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.3.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.4.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.4.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.4.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.4.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.5.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.5.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.5.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.5.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.6.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.6.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.6.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.6.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.7.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.7.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.7.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.7.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.8.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.8.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.8.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.8.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.9.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.9.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.9.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.9.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.10.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.10.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.10.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.10.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.11.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.11.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.11.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.11.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.12.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.12.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.12.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.12.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.13.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.13.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.13.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.13.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.14.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.14.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.14.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.14.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.15.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.15.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.15.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.15.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.16.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.16.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.16.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.16.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.17.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.17.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.17.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.17.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.18.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.18.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.18.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.18.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.19.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.19.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.19.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.19.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.20.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.20.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.20.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.20.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.21.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.21.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.21.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.21.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.22.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.22.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.22.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.22.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.23.self_attn.q_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 4096,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.23.self_attn.k_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.23.self_attn.v_proj\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 512,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"model.layers.23.self_attn.o_proj\": {\n",
      "    \"in_features\": 4096,\n",
      "    \"out_features\": 2880,\n",
      "    \"bias\": true\n",
      "  },\n",
      "  \"lm_head\": {\n",
      "    \"in_features\": 2880,\n",
      "    \"out_features\": 201088,\n",
      "    \"bias\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(first_level_submodule_paths_to_parameter_dicts, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
